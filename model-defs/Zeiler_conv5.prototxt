name: "ImageNet_Zeiler"

input: "data"
input_dim: 128
input_dim: 3
input_dim: 224
input_dim: 224

# ------------------------ layer 1 -----------------------------
layers {
 layer {
   name: "conv1"
   type: "conv"
   conv_param{
	   num_output: 96
	   kernel_size: 7
	   pad: 1
	   stride: 2
	   weight_filler {
		 type: "gaussian"
		 std: 0.01
	   }
	   bias_filler {
		 type: "constant"
		 value: 0
	   }
   }
   blobs_lr: 1.0
   blobs_lr: 2.0
 }
 bottom: "data"
 top: "conv1"
}

layers {
 layer {
   name: "relu1"
   type: "relu"
 }
 bottom: "conv1"
 top: "conv1"
}

layers {
  layer {
    name: "norm1"
    type: "lrn"
	lrn_param{
		local_size: 3
		alpha: 0.00005
		beta: 0.75
		norm_region: WITHIN_CHANNEL
	}
  }
  bottom: "conv1"
  top: "norm1"
}

layers {
 layer {
   name: "pool1"
   type: "pool"
   pool_param{
	   kernel_size: 3
	   stride: 2
	   pool: MAX
   }
 }
 bottom: "norm1"
 top: "pool1"
}


# --------------------------- layer 2 ------------------------
layers {
 layer {
   name: "conv2"
   type: "conv"
   conv_param{
	   num_output: 256
	   kernel_size: 5
	   pad: 0
	   stride: 2
	   weight_filler {
		 type: "gaussian"
		 std: 0.01
	   }
	   bias_filler {
		 type: "constant"
		 value: 1
	   }
   }
   blobs_lr: 1.0
   blobs_lr: 2.0
 }
 bottom: "pool1"
 top: "conv2"
}

layers {
 layer {
   name: "relu2"
   type: "relu"
 }
 bottom: "conv2"
 top: "conv2"
}

layers {
  layer {
    name: "norm2"
    type: "lrn"
	lrn_param{
		local_size: 3
		alpha: 0.00005
		beta: 0.75
		norm_region: WITHIN_CHANNEL
	}
  }
  bottom: "conv2"
  top: "norm2"
}

layers {
 layer {
   name: "pool2"
   type: "pool"
   pool_param{
	   kernel_size: 3
	   stride: 2
	   pool: MAX
   }
 }
 bottom: "norm2"
 top: "pool2"
}


#-----------------------layer 3-------------------------
layers {
 layer {
   name: "conv3"
   type: "conv"
   conv_param{
	   num_output: 384
	   kernel_size: 3
	   pad: 1
	   stride: 1
	   weight_filler {
		 type: "gaussian"
		 std: 0.01
	   }
	   bias_filler {
		 type: "constant"
		 value: 0
	   }
   }
   blobs_lr: 1.0
   blobs_lr: 2.0
 }
 bottom: "pool2"
 top: "conv3"
}

layers {
 layer {
   name: "relu3"
   type: "relu"
 }
 bottom: "conv3"
 top: "conv3"
}

#-----------------------layer 4-------------------------
layers {
 layer {
   name: "conv4"
   type: "conv"
   conv_param{
	   num_output: 384
	   kernel_size: 3
	   pad: 1
	   stride: 1
	   weight_filler {
		 type: "gaussian"
		 std: 0.01
	   }
	   bias_filler {
		 type: "constant"
		 value: 1
	   }
   }
   blobs_lr: 1.0
   blobs_lr: 2.0
 }
 bottom: "conv3"
 top: "conv4"
}

layers {
 layer {
   name: "relu4"
   type: "relu"
 }
 bottom: "conv4"
 top: "conv4"
}

#-----------------------layer 5-------------------------
layers {
 layer {
   name: "conv5"
   type: "conv"
   conv_param{
	   num_output: 256
	   kernel_size: 3
	   pad: 1
	   stride: 1
	   weight_filler {
		 type: "gaussian"
		 std: 0.01
	   }
	   bias_filler {
		 type: "constant"
		 value: 1
	   }
   }
   blobs_lr: 1.0
   blobs_lr: 2.0
 }
 bottom: "conv4"
 top: "conv5"
}

layers {
 layer {
   name: "relu5"
   type: "relu"
 }
 bottom: "conv5"
 top: "conv5"
}

#--------------------------layer spm------------------------

layers {
 layer {
   name: "pool5_spm6"
   type: "pool"
   pool_param{
		kernel_size: 3
		stride: 2
		pool: MAX
   }
 }
 bottom: "conv5"
 top: "pool5_spm6"
}
layers {
 layer {
   name: "pool5_spm6_flatten"
   type: "flatten"
 }
 bottom: "pool5_spm6"
 top: "pool5_spm6_flatten"
}
layers {
 layer {
   name: "pool5_spm3"
   type: "pool"
   pool_param{
		kernel_size: 5
		stride: 4
		pool: MAX
   }
 }
 bottom: "conv5"
 top: "pool5_spm3"
}
layers {
 layer {
   name: "pool5_spm3_flatten"
   type: "flatten"
 }
 bottom: "pool5_spm3"
 top: "pool5_spm3_flatten"
}
layers {
 layer {
   name: "pool5_spm2"
   type: "pool"
   pool_param{
		kernel_size: 7
		stride: 7
		pool: MAX
   }
 }
 bottom: "conv5"
 top: "pool5_spm2"
}
layers {
 layer {
   name: "pool5_spm2_flatten"
   type: "flatten"
 }
 bottom: "pool5_spm2"
 top: "pool5_spm2_flatten"
}
layers {
 layer {
   name: "pool5_spm1"
   type: "pool"
   pool_param{
		kernel_size: 13
		stride: 13
		pool: MAX
   }
 }
 bottom: "conv5"
 top: "pool5_spm1"
}
layers {
 layer {
   name: "pool5_spm1_flatten"
   type: "flatten"
 }
 bottom: "pool5_spm1"
 top: "pool5_spm1_flatten"
}
layers {
 layer {
   name: "pool5_spm"
   type: "concat"
   concat_param{
		concat_dim: 1
   }
 }
 bottom: "pool5_spm1_flatten"
 bottom: "pool5_spm2_flatten"
 bottom: "pool5_spm3_flatten"
 bottom: "pool5_spm6_flatten"
 top: "pool5_spm"
}


#--------------------------layer 6------------------------
layers {
 layer {
   name: "fc6"
   type: "inner_product"
   inner_product_param{
	   num_output: 4096
	   weight_filler {
		 type: "gaussian"
		 std: 0.01
	   }
	   bias_filler {
		 type: "constant"
		 value: 1
	   }
   }
   blobs_lr: 1.0
   blobs_lr: 2.0
 }
 bottom: "pool5_spm"
 top: "fc6"
}
layers {
 layer {
   name: "relu6"
   type: "relu"
 }
 bottom: "fc6"
 top: "fc6"
}
layers {
  layer {
    name: "drop6"
    type: "dropout"
	dropout_param{
		dropout_ratio: 0.5
	}
  }
  bottom: "fc6"
  top: "fc6"
}
#--------------------------layer 7------------------------
layers {
 layer {
   name: "fc7"
   type: "inner_product"
   inner_product_param{
	   num_output: 4096
	   weight_filler {
		 type: "gaussian"
		 std: 0.01
	   }
	   bias_filler {
		 type: "constant"
		 value: 1
	   }
   }
   blobs_lr: 1.0
   blobs_lr: 2.0
 }
 bottom: "fc6"
 top: "fc7"
}
layers {
 layer {
   name: "relu7"
   type: "relu"
 }
 bottom: "fc7"
 top: "fc7"
}
layers {
  layer {
    name: "drop7"
    type: "dropout"
	dropout_param{
		dropout_ratio: 0.5
	}
  }
  bottom: "fc7"
  top: "fc7"
}

#--------------------------layer 8------------------------
layers {
 layer {
   name: "fc8"
   type: "inner_product"
   inner_product_param{
	   num_output: 1000
	   weight_filler {
		 type: "gaussian"
		 std: 0.01
	   }
	   bias_filler {
		 type: "constant"
		 value: 1
	   }
   }
   blobs_lr: 1.0
   blobs_lr: 2.0
 }
 bottom: "fc7"
 top: "fc8"
}
#-----------------------output------------------------
layers {
 layer {
   name: "prob"
   type: "softmax"
 }
 bottom: "fc8"
 top: "prob"
}
